在讯飞星辰MaaS实现零代码大模型微调

概念植入：
	训练方法：
	LoRA：一种用于微调LLM的低秩适应技术，通过仅训练低秩矩阵，然后将这些参数注入到原始模型中，从而实现对模型的微调
	数据配置：
	训练集：用于微调LLM的文本
	测试占比：从训练集中按比例划分数据用于测试，当取值为10时，测试集占总数据的10%，训练集占90%。取值范围为[0-20]，且最多可使用200条数据进行测试
	参数配置：
学习率：是一个超参数，决定了模型在过程过程中权重更新的速度，其值影响到模型的学习进度，过大可能导致损失值爆炸或振荡，过小可能导致过拟合或收敛速度慢 
	训练次数：对于小模型，可能进行多次，这个要根据实际情况来确定
	输入序列分词后的最大长度：模型每次处理的文本序列的最大长度限制（通常以分词后的token数量计算）。建议值为512 -2048，较长的序列允许模型处理更多的上下文信息，能够捕捉到更复杂的依赖关系，但会增加计算开销和内存占用。较短的序列可以提高计算效率，但可能丢失部分上下文信息
	badam：用于解决大尺寸语言模型的微调难题，通过运用独特的块坐标优化策略，能在执行类似Adam优化器更新的同时，大幅度降低内存需求，该技术降低大型模型训练的技术门槛，使受限于硬件资源的研究者受益，希望后面会有更多这样的技术涌现出来，使ai能在较小的硬件下运行，真正走进人们的生活
	Galore：通过优化参数的训练方式来降低VRAM需求，是一种新的模型训练策略，可以让模型使用全部参数进行学习，并且比LoRA更省内存，显著减少计算负荷，同时保留训练所需信息
	Unsloth：专为模型微调设计的框架，旨在解决模型微调过程中常见的训练慢，内存占用高等问题，能显著提高模型微调的效率
	LORA秩：LoRA秩指在微调过程中使用的低秩矩阵的维度，决定适配器的复杂度和更新参数的数量。较低的秩可以减少内存和计算需求，提高微调效率，但可能会影响模型表现；较高的秩则能保留更多信息，适合对精度要求较高的任务，但过高的秩可能导致过拟合。建议值为4-64用于调整分解后矩阵的值，以保持数值稳定性
	缩放系数：用于调整分解后矩阵的值，以保持数值稳定性
	LoRA随机丢弃：LoRA随机丢弃是一种正则化技术，用于在微调过程中随机丢弃低秩适配器中的部分权重，以防止模型过拟合，能在不显著增加计算复杂度的前提下提高模型的整体表现。基于此，模型能够在小数据集上提升泛化能力。LoRA的dropout应设置较小，以确保性能的稳定性，建议值为0-0.01
	LoRA合并：
	在训练过程中，较小的权重矩阵 A、B 是分开的。但一旦训练完成，权重实际上可以合并到一个相同的新权重矩阵中。虽然 LoRA 明显更小，训练速度更快，但由于分别加载基本模型和 LoRA 模型，可能会在推理过程中遇到延迟问题。为了消除延迟，可以使用 merge_and_unload 函数将适配器权重与基本模型合并，这样可以有效地将新合并的模型用作独立模型。同时也可以合并多个 LoRA 模型，使得 Base Model 同时具备多个任务处理能力
	模型验证：
Loss值：用于比较学习结果和样本标签之间的差距，当loss值收敛时结束迭代，其值越小，差距越小，但只表示模型与训练集十分拟合，不代表它在其它的测试集上也会有良好的表现
	发现：在训练次数为5次时，学习率更大一点的loss值越小在其它情况差不多时，训练次数为10次，loss值改变巨大，对于嬛嬛这一模型，得出推论，其数据集的大小十分大，进行多的训练次数会获得更好的拟合，而且对于如此巨大的训练集以及应用来说，这个模型我觉得可以适当过拟合，因为其应用不过是模仿甄嬛传里的人物进行对话，
        若你问一些现代的问题，她对答如流，那就不是古代人了，当然电视脚本是在现代写的，在一定程度上肯定会有一些现代人的特征，我认为模仿当然要拟合人物的性格特征，对于历史人物，虚幻人物的模仿，我认为都不应该让他们接触规则内他们不知道的事物，这样才算真正的模仿，当然，有一个了解现代知识的模仿ai当然也能存在
        这里想到一个点子，就生成一个古代人，它不知道所有现代的知识，但偶尔你说一些概念，它会以它的历史环境的存在的事物进行对比，以另一种不同环境下的思想存在，那将会很有意思，使用者可以从0开始对这个古代人进行概念输送，直到它成为一个真正的现代人，它不仅可以存在于app中，还能做成宠物跟随，还能做成养成类游戏，但要实现这个ai，要克服的难点有不少
